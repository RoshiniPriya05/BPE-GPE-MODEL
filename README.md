BPE-GPE Model Comparison Project
A Python-based NLP project comparing Byte Pair Encoding (BPE) and Grapheme-level (character-based) tokenization models on Tamil text. This tool benchmarks both models for vocabulary efficiency, token length, and reconstruction accuracy.

ğŸš€ How to Run This Project (VS Code)
1. Clone the repository

git clone https://github.com/RoshiniPriya05/BPE-GPE-MODEL.git
cd BPE-GPE-MODEL
2. Create and activate a virtual environment

python -m venv venv
Activate the environment:

On Windows:


.\venv\Scripts\activate
On Mac/Linux:


source venv/bin/activate
3. Install dependencies

pip install -r requirements.txt
If requirements.txt is missing:


pip install numpy matplotlib
4. Run the Models and Benchmark
Train the BPE model:


python train_bpe.py
Train the Grapheme (Character-level) model:


python train_gpe.py
Run benchmarking to compare results:

python benchmark.py
ğŸ“ Project Structure

â”œâ”€â”€ train_bpe.py           # Train and test the BPE model
â”œâ”€â”€ train_gpe.py           # Train and test the Grapheme model
â”œâ”€â”€ benchmark.py           # Compare and visualize both models
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bpe_model.py
â”‚   â”œâ”€â”€ gpe_model.py
â”‚   â””â”€â”€ base_model.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ data_loader.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ tamil_corpus.txt   # Sample corpus used for training/testing
â”œâ”€â”€ results/               # Benchmark results and plots
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ§ª Sample Input (from data/tamil_corpus.txt)

à®‡à®¨à¯à®¤ à®‰à®²à®•à®®à¯ à®…à®´à®•à®¾à®©à®¤à¯.
You can modify or expand the corpus in data/tamil_corpus.txt to test with different inputs.

ğŸ“Š Output
Tokenized outputs for both models

Metrics like token count and reconstruction quality

Benchmark visualizations saved in the results/ folder
